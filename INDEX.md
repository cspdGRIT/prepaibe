# ğŸ“¦ AIBE Smart Prep - Complete Package

## ğŸ¯ What You've Got

A complete flashcard system with **automatic AI generation** that seamlessly provides 15+ questions per topic, with configurable LLM support.

## ğŸ“ Files Included

### 1. ğŸŒ aibe-smart-prep-enhanced.html
**Main Application (Standalone)**
- Open in any browser - no server needed
- Auto-generates cards when you reach last 3 cards
- Ensures minimum 15 cards per topic
- Multiple LLM provider support
- AI chat assistant built-in
- All features in one file

**Quick Start:**
```
1. Open file in browser
2. Go to AI Settings tab
3. Add API key (free from Groq)
4. Start studying!
```

### 2. ğŸ flashcard_generator.py
**Python Helper Script**
- Batch generate flashcards into JSON files
- Support for Groq, OpenRouter, Ollama, OpenAI
- Expand existing JSON to meet minimum cards
- Command-line friendly

**Usage:**
```bash
export LLM_PROVIDER=groq
export LLM_API_KEY=your_key
python flashcard_generator.py
```

### 3. ğŸ“– README.md
**Comprehensive Documentation**
- Full feature list
- Detailed setup instructions
- All LLM provider configurations
- Troubleshooting guide
- Best practices
- FAQ section

### 4. ğŸš€ QUICKSTART.md
**Get Started in 5 Minutes**
- Three quick start options
- Step-by-step guides
- Pro tips for best experience
- Common issues solved

### 5. âš™ï¸ env.example
**Configuration Template**
- API key setup examples
- All provider configurations
- Environment variables reference
- Copy-paste ready examples

### 6. ğŸ“‹ flashcards_template.json
**Sample Data Structure**
- 8 AIBE topics included
- 3-5 cards per topic
- Proper JSON format
- Ready to expand with Python script

## ğŸ”‘ Key Features Implemented

### âœ… Auto-Generation
- **When:** Last 3 cards remaining
- **How many:** Configurable (default 15)
- **Seamless:** No manual intervention needed

### âœ… Minimum Cards Guarantee
- **Ensures:** 15+ cards per topic
- **When:** Topic start (if enabled)
- **Smart:** Only generates what's needed

### âœ… Multiple LLM Support
- **Groq:** Free, fast (recommended)
- **OpenRouter:** Multiple free models
- **Ollama:** 100% local, free
- **Custom:** Any OpenAI-compatible API

### âœ… Configurable Everything
- Cards per batch (5-30)
- Auto-generation on/off
- Minimum card threshold
- Provider selection
- Model selection

### âœ… Smart Storage
- All AI cards persist locally
- No data loss on refresh
- Download entire app
- Export capability

## ğŸ“ Usage Scenarios

### Scenario 1: Casual Study
```
1. Open HTML file
2. Configure Groq (free)
3. Study any topic
4. Auto-gen handles rest
```

### Scenario 2: Batch Preparation
```bash
# Generate 15+ cards for all topics
python flashcard_generator.py

# Import JSON into HTML
# Study with expanded data
```

### Scenario 3: Offline/Local
```bash
# Install Ollama
ollama pull llama3.1

# Configure HTML to use Ollama
# Study completely offline
```

### Scenario 4: Heavy Use
```bash
# Use Python script for bulk generation
for topic in topics:
    generate_cards(topic, count=30)

# Pre-generate hundreds of cards
# Study without hitting API limits
```

## ğŸ”§ Configuration Guide

### Option 1: HTML App (In Browser)
```
AI Settings â†’ 
  Provider: Groq
  API Key: gsk_...
  Cards per batch: 15
  Auto-generate: âœ…
  Min 15 cards: âœ…
â†’ Save Settings
```

### Option 2: Python Script
```bash
# Method 1: Environment variables
export LLM_PROVIDER=groq
export LLM_API_KEY=gsk_...

# Method 2: Edit script directly
config = {
    'provider': 'groq',
    'api_key': 'your_key'
}
```

## ğŸ†“ Free API Options

| Provider | How to Get | Limits |
|----------|------------|--------|
| **Groq** | console.groq.com | 30/min, 14.4k/day |
| **OpenRouter** | openrouter.ai | Various free models |
| **Ollama** | ollama.ai | Unlimited (local) |

## ğŸ“Š What Gets Auto-Generated

**When you start a topic with < 15 cards:**
```
Initial cards: 5
Auto-generates: 10
Total: 15 âœ…
```

**When you reach last 3 cards:**
```
Current: 15 cards
At card 13: Auto-gen 15 more
New total: 30 cards
```

**Manual generation:**
```
Click button: +15 cards instantly
No limits on how many times
```

## ğŸ¯ Success Criteria Met

âœ… **15+ questions per topic** - Guaranteed by auto-generation  
âœ… **Seamless experience** - Auto-generates in background  
âœ… **Configurable LLM** - 4 providers supported  
âœ… **Free options** - Groq, OpenRouter, Ollama  
âœ… **On-the-fly generation** - Real-time during study  
âœ… **Topic-specific** - Based on syllabus context  
âœ… **Never runs out** - Infinite card generation  

## ğŸš¦ Next Steps

1. **Try the HTML app first** (easiest)
2. **Get a free Groq API key**
3. **Test with one topic**
4. **Enable auto-generation**
5. **Study and watch it work!**

For batch processing:
1. **Set up Python environment**
2. **Run script on template JSON**
3. **Import into HTML app**

## ğŸ’¡ Pro Tips

1. Start with Groq - fastest free option
2. Enable all auto-features for best UX
3. Set 15-20 cards per batch (balanced)
4. Use Ollama for unlimited local use
5. Python script for bulk pre-generation
6. Test connection before long study sessions

## ğŸ› If Something Goes Wrong

1. **Check:** QUICKSTART.md (common issues)
2. **Read:** README.md (full troubleshooting)
3. **Test:** Connection in AI Settings
4. **Try:** Different LLM provider
5. **Verify:** API key and quota

## ğŸ“ Quick Help

**Cards not generating?**
â†’ Check API key in Settings

**Too slow?**
â†’ Try Groq or Ollama

**Want offline?**
â†’ Install Ollama

**Need more cards?**
â†’ Increase batch size or use Python script

## ğŸ“ Study Flow

```
Pick Topic â†’ Study Cards â†’ Auto-gen kicks in â†’ 
Keep studying â†’ Never run out â†’ Use AI chat for doubts â†’
Repeat for all topics â†’ Ace the AIBE! ğŸ¯
```

## âœ¨ Highlights

This system **solves your exact problem:**
- âŒ Before: Only 5 cards, manual generation
- âœ… Now: Auto 15+, seamless, configurable

**You asked for:**
- At least 15 questions âœ…
- Groq/free LLM âœ…
- Seamless generation âœ…
- Topic-based âœ…
- Configurable âœ…

**You got:**
- Unlimited questions âœ¨
- 4 LLM options âœ¨
- Auto + manual generation âœ¨
- Full syllabus support âœ¨
- Standalone HTML + Python âœ¨

---

**Ready to ace AIBE?** Open the HTML file and start! ğŸš€

Questions? Check README.md for full docs.
Good luck! ğŸ“
